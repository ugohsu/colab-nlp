# 埋め込み表現の進化: 静的表現から文脈化表現へ

このドキュメントでは、自然言語処理における二つの主要なベクトル化アプローチ、**Word2Vec（静的埋め込み）** と **Transformer/BERT（文脈化埋め込み）** の本質的な違いについて解説します。

---

## 1. 最大の違いは「文脈（Context）」の動的な理解

両者の決定的な違いは、**「同じ単語が異なる文脈で使われたとき、ベクトルが変化するか」** という点にあります。

### 例：単語「Apple」の意味

#### 静的埋め込み (Static Embedding)
**代表例: Word2Vec, GloVe**

これらの手法は、辞書のように「Apple = [0.1, 0.5, ...]」という**固定のベクトル**を割り当てます。文中のどこに現れても、数値は不変です。

* "I ate an **Apple**." （果物） -> ベクトルA
* "**Apple** released a new iPhone." （IT企業） -> ベクトルA

結果として、「果物」と「企業」の意味が平均化されたようなベクトルになり、多義語の区別がつきません。

#### 文脈化埋め込み (Contextualized Embedding)

**代表例: Transformer, BERT, GPT**

> ※ BERT は主に「エンコーダ型（理解）」、GPT は主に「デコーダ型（生成）」の Transformer モデルです。本ドキュメントでは「文脈化埋め込み」という共通点に着目しています。

これらの手法は、**周囲の単語との関係性（Attention）** に基づいて、その都度ベクトルを動的に生成します。

* "I **ate** an **Apple**."
    * 👉 「食べる」との関係性が考慮され、「果物」の意味合いが強いベクトルA'が生成されます。
* "**Apple** released a new **iPhone**."
    * 👉 「iPhone」との関係性が考慮され、「IT企業」の意味合いが強いベクトルA''が生成されます。

---

## 2. 仕組みのイメージ：Attention（注意）機構

文脈化を実現しているのは、**Self-Attention（自己注意機構）** という仕組みです。

人間が文章を読むとき、無意識に単語間の修飾関係を探します。
> 「彼は、昨日買った本を**読んだ**」

このとき、「読んだ」という単語を処理する際、「誰が？（彼）」「何を？（本）」という関連語に**注目（Attention）**し、その情報を統合して意味を理解します。

Transformerモデルも同様に、一つの単語をベクトル化する際に、**「文章中の他のどの単語から情報を集めるべきか」** を計算し、動的にベクトルを合成しています。

---

## 3. 分析における使い分け

`colab-nlp` において、どちらのアプローチを採用すべきかの判断基準です。

| 特徴 | 静的埋め込み (Word2Vec) | 文脈化埋め込み (Transformer) |
| :--- | :--- | :--- |
| **ベクトルの性質** | **静的・固定** (1単語1ベクトル) | **動的・可変** (文脈により変化) |
| **得意なタスク** | 単語間の類似度算出、類推（王様-男+女=女王） | 文章分類、感情分析、要約、Q&A |
| **計算コスト** | **軽量** (CPUのみで実用可能) | **高負荷** (GPU推奨、計算時間は長い) |
| **学習アプローチ** | 手持ちのデータでゼロから学習することが多い | 大規模な事前学習済みモデルをロードして利用する |

### 結論：どちらを選択するか？

* **Word2Vec (静的)**:
    * データ全体の単語の傾向を俯瞰したい場合。
    * 計算リソースが限られている、または数秒で結果を出したい場合。
* **BERT (文脈化)**:
    * 文脈による精密な分類（例：ネガティブ/ポジティブの判定）を行いたい場合。
    * 計算時間をかけてでも、高い精度を必要とする場合。

---

## 4. `colab_nlp` での実装方針

`colab_nlp` の `llm` モジュール (Coming Soon) では、Hugging Face Hub で公開されている**事前学習済みモデル（Pre-trained Models）** を利用します。

私たちは「学習（Training）」を一から行うのではなく、モデルが持つ高度な言語理解能力を借りて、手持ちのテキストを**「推論・変換（Inference/Encoding）」** することに注力します。これにより、少量のデータセットであっても、文脈を考慮した高度な分析が可能になります。

---

## 補足：LLM（Large Language Model）とは何か

LLM（Large Language Model）とは、**「次に来る単語（トークン）を予測する」ことを目的として学習された、非常に大規模な Transformer モデル**です。

LLM は文章を「理解している」わけではなく、文脈に基づいて **次に現れやすいトークンの確率分布**を計算し続けています。

重要なのは、LLM の内部では本ドキュメントで説明してきた**文脈化埋め込み（Contextualized Embedding）と Attention 機構**が中核的な役割を果たしている点です。

そのため、LLM は

- 文書分類
- 類似度計算
- 埋め込み抽出
- テキスト生成

といった多様なタスクを、**同一のモデル構造のまま**実現できます。

本プロジェクトでは、LLM を「文章生成の魔法の箱」としてではなく、**高度な文脈表現を与えてくれるベクトル化エンジン**として利用する立場を取ります。

---

## 補足：LLMを「使わない」判断基準

LLM（Large Language Model）は非常に強力ですが、**すべてのテキスト分析において最適な選択とは限りません**。

以下のような場合には、`colab-nlp` で既に提供している BoW / Word2Vec / LDA などの手法の方が、**解釈可能性・再現性の面で適している**ことがあります。

### LLMを使わない方がよいケース

- **語の頻度・共起構造そのもの**を分析したい場合  
  （例：キーワード分析、頻度比較、特徴語抽出）
- **分析結果の解釈可能性が重要な場合**  
  （例：文書表現を構成する各成分が何を表しているかについて、明示的な解釈が求められる分析）
- **分析結果の再現性が重要な場合**  
  （例：同一データ・同一手順から常に同じ結果が得られることが求められる分析）

### 本プロジェクトにおける立場

本プロジェクトでは、LLM を「万能な置き換え手段」としてではなく、

- 従来手法で **構造や傾向を把握した上で**
- 必要に応じて **文脈理解を補強する手段**

として位置づけます。そのため、まずは

> BoW / Word2Vec / LDA など**軽量で解釈可能な手法を使いこなすこと**

を重視し、その延長線上に LLM を「選択肢の一つ」として導入する方針を取ります。

