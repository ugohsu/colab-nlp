# Bag of Words（BoW）

本章では、**Bag of Words（BoW）** という考え方を軸に、日本語テキストを「単語の集合」として扱うための基本的な手法を整理します。

BoW は、自然言語処理における

- 語頻度分析
- TF-IDF
- N-gram
- 共起分析
- WordCloud

といった多くの手法の**共通土台**となる考え方です。

本リポジトリでは、**形態素解析 → BoW → 各種分析・可視化**という流れを、Google Colaboratory 上で再現可能な形で提供します。

---

## Bag of Words（BoW）とは

Bag of Words（BoW）とは、文章を

> **「単語の集まり（袋）」**

として表現する、自然言語処理における最も基本的な考え方のひとつです。

BoW では、

- 単語の出現順序
- 文法構造
- 文脈的な意味関係

をすべて捨て、

- **どの単語が**
- **どれだけ出現したか**

だけに注目します。

この大胆な単純化によって、文章を **数値データ（ベクトル）として扱う** ことが可能になります。

---

## 本章で扱う内容

本章では、BoW の考え方を土台として、以下の手法を扱います。

### 1. 語頻度（Term Frequency）

- 単語 × 出現回数
- BoW の最も基本的な形
- pandas から sklearn への接続を意識

👉 解説ドキュメント
- [`term_frequency.md`](./term_frequency.md)


### 2. WordCloud

- 単語頻度の可視化
- BoW 的表現の直感的理解

👉 解説ドキュメント
- [`wordcloud.md`](./wordcloud.md)


### 3. N-gram

- 隣り合うN個の単語（Bigram, Trigram...）の出現頻度
- 複合語（「人工」+「知能」）の発見や文脈の把握
- 大規模データ（CorpusDB）への対応手法

👉 解説ドキュメント
- [`ngram.md`](./ngram.md)


### 4. 共起ネットワーク

- 単語同士の「共起関係（つながり）」を可視化
- N-gram 集計結果を入力として、話題の構造や中心的な語を把握

👉 解説ドキュメント
- [`network_graph.md`](./network_graph.md)


---

## 位置づけ

Bag of Words は、

- 実装が簡単
- 結果が直感的に理解しやすい

という強みを持つ一方で、

- 語順
- 文脈
- 意味構造

を表現できないという限界もあります。

本章では、

- **BoW の強みを実感する**
- **限界を理解する**

ことを通じて、後続の高度な NLP 手法（TF-IDF、トピックモデル、分散表現など）へ自然につなげることを目的とします。

---

## 用いるデータ形式

以降の各論では、`tokenize_df()` ([`tokenization.md`](../tokenization.md) 参照) で生成されたデータフレームを前提に説明を進めます。

- 文書は `doc_id` により一意に識別されます
- 文書内のトークン順序は `token_id` により保持されます

| 列名        | 型      | 制約 | 説明 |
|-------------|---------|------|------|
| doc_id      | INTEGER | FK   | 文書ID（`documents.doc_id` への外部キー） |
| token_id    | INTEGER |      | 文書内でのトークン通し番号（0始まり） |
| word        | TEXT    |      | トークン文字列（表層形または辞書形） |
| pos         | TEXT    |      | 品詞（大分類。例: 名詞, 動詞, 形容詞） |
| token_info  | TEXT    |      | 詳細情報の JSON 文字列（原形・読み・正規化情報など） |

### 利用例

- **BoW（単語頻度）**  
  `doc_id` と `word` を用いて単語カウントを行う
- **品詞フィルタ付き BoW**  
  `pos` を条件に名詞のみ・動詞のみを抽出
- **n-gram / 文脈処理**  
  `token_id` による順序情報を利用
- **正規化・実験切替**  
  `token_info` 内の原形・読みを用いた再集計
